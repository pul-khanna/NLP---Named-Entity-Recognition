{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><b> Named Entity Recognition </b></center></h1>\n",
    "\n",
    "#### NER is used for extraction such entities from the text as persons, organizations, locations, etc. Here we try to recognize named entities from Twitter with LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we will use a recurrent neural network model which will be made using KERAS Functional API to solve our NER problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide tensorflow warnings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model, optimizers\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM,\n",
    "    Activation,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    ")\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Sometimes we have to run the above cell for importing libraries again as tensorflow or keras module is unable to get imported the first time due to some bug. If later on, if we get an error when compiling our mode or our settings optimizers etc, re-run the import library cell again.\n",
    "#### Note: Tensorflow 2.5 and numpy 1.20 and 1.21 will result in an error when building the model as Tensforflow uses numpy ver 1.19.5 internally for calculations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT O\\n', '@TheValarium O\\n', ': O\\n', 'Online O\\n', 'ticket O\\n', 'sales O\\n', 'for O\\n', 'Ghostland B-musicartist\\n', 'Observatory I-musicartist\\n', 'extended O\\n', 'until O\\n', '6 O\\n', 'PM O\\n', 'EST O\\n', 'due O\\n', 'to O\\n', 'high O\\n', 'demand O\\n', '. O\\n', 'Get O\\n', 'them O\\n', 'before O\\n', 'they O\\n', 'sell O\\n', 'out O\\n', '... O\\n', '\\n', 'Apple B-product\\n', 'MacBook I-product\\n', 'Pro I-product\\n', 'A1278 I-product\\n', '13.3 I-product\\n', '\" I-product\\n', 'Laptop I-product\\n', '- I-product\\n', 'MD101LL/A I-product\\n', '( O\\n', 'June O\\n', ', O\\n', '2012 O\\n', ') O\\n', '- O\\n', 'Full O\\n', 'read O\\n', 'by O\\n', 'eBay B-company\\n', 'http://t.co/2zgQ99nmuf O\\n', 'http://t.co/eQmogqqABK O\\n', '\\n', 'Happy O\\n', 'Birthday O\\n', '@AshForeverAshey O\\n', '! O\\n', 'May O\\n', 'Allah B-person\\n', 's.w.t O\\n', 'bless O\\n', 'you O\\n', 'with O\\n', 'goodness O\\n', 'and O\\n', 'happiness O\\n', '. O\\n', '\\n', '@AqwSkills O\\n', 'the O\\n', 'quest O\\n', 'line O\\n', 'im O\\n', 'assuming O\\n', 'it O\\n', 'will O\\n', 'be O\\n', 'the O\\n', 'same O\\n', 'way O\\n', 'with O\\n', 'awe O\\n', 'thur O\\n', '\\n', '@Wolven O\\n', '@VanessaY O\\n', '@miniver O\\n', '@mathpunk O\\n', '@NeilHarbisson O\\n', 'still O\\n', 'perception O\\n', ', O\\n', 'and O\\n', 'what O\\n', 'you O\\n', 'key O\\n', 'off O\\n', 'may O\\n', 'differ O\\n', 'from O\\n', 'me O\\n', '. O\\n', 'Back O\\n', 'to O\\n']\n"
     ]
    }
   ],
   "source": [
    "# Note: 'with' automatically closes file \n",
    "\n",
    "with open('data/train.txt') as f:\n",
    "    line = [f.readline() for i in range(100)]\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading twitter text file format, we note every line contains a pair of a token (word/punctuation symbol) and a tag, separated by a whitespace and different tweets are separated by an empty line. \n",
    "\n",
    "#### Further, we see different user names start after an '@' symbol and also there are different url's. These can be replaced by an identification token as they won't be useful by themselves in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Function to read twitter text file and return a separated list of tokens and its corresponding tags \"\"\"\n",
    "\n",
    "def read_data(file_path):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    \n",
    "    tweet_tokens = []\n",
    "    tweet_tags = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            if tweet_tokens:\n",
    "                tokens.append(tweet_tokens)\n",
    "                tags.append(tweet_tags)\n",
    "            tweet_tokens = []\n",
    "            tweet_tags = []\n",
    "        else:\n",
    "            token, tag = line.split()\n",
    "            # Replace all urls with <URL> token\n",
    "            # Replace all users with <USR> token\n",
    "\n",
    "            if token.startswith(\"@\"):\n",
    "                token=\"<USR>\"\n",
    "            elif token.startswith(\"http://\") or token.startswith(\"https://\"):\n",
    "                token=\"<URL>\"\n",
    "            \n",
    "            tweet_tokens.append(token)\n",
    "            tweet_tags.append(tag)\n",
    "            \n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens, train_tags = read_data('data/train.txt')\n",
    "val_tokens, val_tags = read_data('data/validation.txt')\n",
    "test_tokens, test_tags = read_data('data/test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving our tokens and tags into train,validation and test sets.\n",
    " - *train* data for training the model;\n",
    " - *validation* data for evaluation and hyperparameters tuning;\n",
    " - *test* data for final evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Sentence 1 :- -----\n",
      "RT\tO\n",
      "<USR>\tO\n",
      ":\tO\n",
      "Online\tO\n",
      "ticket\tO\n",
      "sales\tO\n",
      "for\tO\n",
      "Ghostland\tB-musicartist\n",
      "Observatory\tI-musicartist\n",
      "extended\tO\n",
      "until\tO\n",
      "6\tO\n",
      "PM\tO\n",
      "EST\tO\n",
      "due\tO\n",
      "to\tO\n",
      "high\tO\n",
      "demand\tO\n",
      ".\tO\n",
      "Get\tO\n",
      "them\tO\n",
      "before\tO\n",
      "they\tO\n",
      "sell\tO\n",
      "out\tO\n",
      "...\tO\n",
      "----------------------- \n",
      "\n",
      "----- Sentence 2 :- -----\n",
      "Apple\tB-product\n",
      "MacBook\tI-product\n",
      "Pro\tI-product\n",
      "A1278\tI-product\n",
      "13.3\tI-product\n",
      "\"\tI-product\n",
      "Laptop\tI-product\n",
      "-\tI-product\n",
      "MD101LL/A\tI-product\n",
      "(\tO\n",
      "June\tO\n",
      ",\tO\n",
      "2012\tO\n",
      ")\tO\n",
      "-\tO\n",
      "Full\tO\n",
      "read\tO\n",
      "by\tO\n",
      "eBay\tB-company\n",
      "<URL>\tO\n",
      "<URL>\tO\n",
      "----------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(\"----- Sentence {0} :- -----\".format(i+1))\n",
    "    for token, tag in zip(train_tokens[i], train_tags[i]):\n",
    "        print('%s\\t%s' % (token, tag))\n",
    "    print (\"----------------------- \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking our training set list for tokens and tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To train our neural network, we will create a dictionary with two mappings:\n",
    "- token → token id: use integers as input data of KERAS embedding layer so that words can be represented     by dense vectors (More memory and computationally efficient than One-Hot Encoding)\n",
    "- tag → tag id: use integers for computing the loss at the output of the network.\n",
    "\n",
    "#### Note: Here we are considering that we have single-class labels, where an object can only belong to one class, i.e. each token belongs to a particular tag or vice-versa. Hence, we can use \"sparse_categorical_crossentropy\" instead of \"categorical_crossentropy\" as our loss function which requires one-hot-encoded vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: We will also need to add some 'Special tokens and tags' to our dictionary. They will be unknown tokens and padding tokens/tags.\n",
    "- &lt;UNK&gt; token to represent of vocabulary tokens;\n",
    "- &lt;PAD&gt; tokens and tags for padding sentence to the same length when we create batches of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Dictionary to create mappings for tokens and tags \"\"\"\n",
    "\n",
    "def build_dict(tokens_or_tags, special_tokens):\n",
    "    \"\"\"\n",
    "        tokens_or_tags: a list of lists of tokens or tags\n",
    "        special_tokens: some special tokens\n",
    "    \"\"\"\n",
    "    # Create a dictionary with default value 0\n",
    "    tok2idx = defaultdict(lambda: 0)\n",
    "    idx2tok = []\n",
    "    \n",
    "# Note: First add special tokens and tags to the dictionaries and the first special token must have index 0\n",
    "# Here, first special token must be for \"pad\" as later on we can use an in-built KERAS function for masking\n",
    "# pads to avoid extra copmutations i.e. mask_zero which only applies for value 0 (index 0 here)\n",
    "    \n",
    "    k = 0\n",
    "    for line in special_tokens:\n",
    "        tok2idx[line] = k\n",
    "        k += 1\n",
    "        idx2tok.append(line)\n",
    "        \n",
    "    for tokens in tokens_or_tags:\n",
    "        for token in tokens:\n",
    "            if token not in tok2idx: \n",
    "                tok2idx[token] = k \n",
    "                k += 1\n",
    "                idx2tok.append(token)\n",
    "    \n",
    "    return tok2idx, idx2tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = ['<PAD>', '<UNK>']\n",
    "special_tags = ['<PAD>']\n",
    "\n",
    "# Create dictionaries \n",
    "token2idx, idx2token = build_dict(train_tokens + val_tokens, special_tokens)\n",
    "tag2idx, idx2tag = build_dict(train_tags + val_tags , special_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Implemented the function build_dict and creating dictionaries for our tokens and tags.\n",
    "#### Note: We always consider test tokens and tags to be unseen/unknown and hence don't use them when creating our dicitonaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding Input Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The LSTM layers only accepts sequences within a batch that are of same lengths. It means that weight updates of the network are based on several sequences at every single time. So we will pad shorter sequences within a batch with a special token (&lt;PAD&gt;) to match the length of the largest sequence in that batch, thus making all sequences of equal length for every batch. This technique is also known as bucketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will define a function to generate batches of equal length which can then be fed into our neural network model. For this, we will define 3 functions :-\n",
    "* helper function to generate the number of batches for a given batch size\n",
    "* helper function to create list of the mapped id's from tokens when given a sentence\n",
    "* function for generating batches with sequences of equal lengths by applying padding using the 2 helper functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_batches(batch_size, tokens, allow_smaller_last_batch = True):\n",
    "    n_samples = len(tokens)\n",
    "    n_batches = n_samples // batch_size                          ### '//' for floor division \n",
    "    if allow_smaller_last_batch and n_samples % batch_size:\n",
    "        n_batches += 1\n",
    "    return n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2idxs(tokens_list):\n",
    "    return [token2idx[word] for word in tokens_list]\n",
    "\n",
    "def tags2idxs(tags_list):\n",
    "    return [tag2idx[tag] for tag in tags_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_generator(batch_size, n_batches, tokens, tags,\n",
    "                      shuffle = True):\n",
    "    \"\"\"Generates padded batches of tokens and tags.\"\"\"\n",
    "    while True:                       ### 'while' loop used for looping through epochs in train.fit() \n",
    "        n_samples = len(tokens)\n",
    "        if shuffle:\n",
    "            order = np.random.permutation(n_samples)\n",
    "        else:\n",
    "            order = np.arange(n_samples)\n",
    "    \n",
    "        for k in range(n_batches):\n",
    "            batch_start = k * batch_size\n",
    "            batch_end = min((k + 1) * batch_size, n_samples)\n",
    "            current_batch_size = batch_end - batch_start\n",
    "            x_list = []\n",
    "            y_list = []\n",
    "            max_len_token = 0\n",
    "            for idx in order[batch_start: batch_end]:\n",
    "                x_list.append(words2idxs(tokens[idx]))\n",
    "                y_list.append(tags2idxs(tags[idx]))\n",
    "                max_len_token = max(max_len_token, len(tags[idx]))\n",
    "                \n",
    "            # Fill in the data into numpy nd-arrays filled with padding indices.\n",
    "            x = np.ones([current_batch_size, max_len_token], dtype=np.int32) * token2idx['<PAD>']\n",
    "            y = np.ones([current_batch_size, max_len_token], dtype=np.int32) * tag2idx['<PAD>']        \n",
    "            for n in range(current_batch_size):\n",
    "                utt_len = len(x_list[n])\n",
    "                x[n, :utt_len] = x_list[n]\n",
    "                y[n, :utt_len] = y_list[n]\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: We will provide RNN and loss function with sequence lengths, so it can skip computations for padding parts. For this we can use KERAS mask_zero param to remove the paddings parts for computation.\n",
    "#### Helper function 'n_batches' has to be separate from 'batches_generator' function as later on we will be using 'fit' method for training our model which requires number of batches as input for steps_per_epoch param when using a generator as input for X(input data) param. However, when using 'train_on_batch' method instead of 'fit' method we can include them in a single function as well. For a similar reason we have used a 'while' loop in 'batches_generator' function to loop through epochs which will be declared in our 'fit' method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Implementing Model Architecture\n",
    "\n",
    "#### We will create an LSTM network which will produce probability distribution over tags for each token in a sentence. To take into account both right and left contexts of the token, we will use Bi-Directional LSTM (Bi-LSTM). Dense layer will be used on top to perform tag classification. We will use Keras Functional API to build our model.\n",
    "\n",
    "#### We will set our input shape as 'None' so that we can accept sequences of variable length\n",
    "\n",
    "#### 'mask_zero' param will be set to True in 'Embedding' layer so as to to avoid computations for padding tokens inside the RNN and also when computing loss function.\n",
    "\n",
    "#### We will set 'dropout' param in our RNN layer for regularization.\n",
    "\n",
    "#### We will use 'softmax' in our activation function for output lyer, as it will provide us a multinominal probability distribution for our multi-label classification problem\n",
    "\n",
    "#### Our Loss Function will be \"sparse_categorical_crossentropy\" (No need for OHC, can use integers)\n",
    "\n",
    "#### Note: We can use 'Time Distributed Layer'(Many to Many architecture) instead of 'Dense Layer'(Many to One architecture) as output layer and check its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments:\n",
    "\n",
    "- input_dim: This is the size of the vocabulary in the text data. Here, it will length of token dictionary   consisting of \n",
    "- output_dim: This is the size of the vector space in which words will be embedded. It defines the size of   the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger.       Here, we will use 200.\n",
    "- input_length: This is the length of input sequences, as you would define for any input layer of a Keras model. Here, it will max sentence length from our training and validations dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The output dense layer length should be equal to number of labels i.e. tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(idx2token)\n",
    "output_dim = 200\n",
    "num_tags = len(idx2tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialized input and output parameters for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Optimizer for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use adam optimization algorithm with learning rate decay. The learning rate is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated. An initially large learning rate suppresses the network from memorizing noisy data while decaying the learning rate improves the learning of complex patterns.\n",
    "#### Note: We can also use 'Adaptive Moment Estimation' instead of learning rate schedules method as it can be challenging to configure and is critical to the performance of a deep learning neural network model. \n",
    "\n",
    "#### We also apply clipping to eliminate exploding gradients. Here, we use 'global_clipnorm' function in KERAS which clips only gradients and not variables. Also, function 'clip_norm' clips the gradient of each weight independently of the gradients of the other weights and thus has the disadvantage of changing the descent direction, whereas with global_clipnorm the direction would remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = 1e-2,\n",
    "    decay_steps = 10000,\n",
    "    decay_rate = 0.9)\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate = lr_schedule, global_clipnorm = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KERAS BI-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 200)         4101000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 200)         240800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 22)          4422      \n",
      "=================================================================\n",
      "Total params: 4,346,222\n",
      "Trainable params: 4,346,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_seq = Input(shape = (None,))\n",
    "model = Embedding(input_dim = input_dim, output_dim = output_dim, mask_zero = True)(input_seq)\n",
    "\n",
    "forward_layer = keras.layers.RNN(\n",
    "            keras.layers.LSTMCell(100, dropout = 0.5), return_sequences = True)\n",
    "backward_layer = keras.layers.RNN(\n",
    "            keras.layers.LSTMCell(100, dropout = 0.5), return_sequences = True, go_backwards = True)\n",
    "\n",
    "model = (Bidirectional(forward_layer, backward_layer = backward_layer))(model)\n",
    "\n",
    "out = (Dense(num_tags, activation = \"softmax\"))(model)\n",
    "model = Model(input_seq, out)\n",
    "\n",
    "model.compile(optimizer = opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"Accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After compiling, we will train our data and conduct more experiments as needed to tune our hyperparameters, to obtain higher accuracy on the held-out validation dataset.\n",
    "#### The hyperparameters for our model are :- batch_size, epochs, learning_rate params, global_clip_norm, dropout.\n",
    "#### For training our model we will be using 'fit' method but in 'x' param (input data) and 'validation_data' param we will use a generator as sequences are of different lengths. Also, as we will be using a generator we will have assign values for 'steps_per_epoch' and 'validation_steps' pararms instead of batch_size.\n",
    "#### To use a generator for training our model we will define a function which will make use of 'n_batches' and 'batches_generator' functions defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" To train a model using a Generator \"\"\"\n",
    "\n",
    "def train_model(x_train , y_train, x_val = None, y_val = None, batch_size = 32, epochs = 2, verbose = 1):    \n",
    "    n_batch_train = n_batches(batch_size, x_train)    \n",
    "    if x_val:\n",
    "        n_batch_val = n_batches(batch_size, x_val)\n",
    "\n",
    "    history = model.fit(\n",
    "        x = batches_generator(batch_size, n_batch_train, x_train, y_train, epochs),\n",
    "        y = None,\n",
    "        steps_per_epoch = n_batch_train,\n",
    "        validation_data = batches_generator(batch_size, n_batch_val, x_val, y_val, epochs),\n",
    "        validation_steps = n_batch_val,\n",
    "        epochs = epochs,\n",
    "        verbose = verbose,\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "182/182 [==============================] - 71s 327ms/step - loss: 0.2319 - Accuracy: 0.9223 - val_loss: 0.1576 - val_Accuracy: 0.9367\n",
      "Epoch 2/5\n",
      "182/182 [==============================] - 56s 307ms/step - loss: 0.1005 - Accuracy: 0.9539 - val_loss: 0.1464 - val_Accuracy: 0.9402\n",
      "Epoch 3/5\n",
      "182/182 [==============================] - 61s 335ms/step - loss: 0.0460 - Accuracy: 0.9772 - val_loss: 0.1717 - val_Accuracy: 0.9240\n",
      "Epoch 4/5\n",
      "182/182 [==============================] - 70s 385ms/step - loss: 0.0252 - Accuracy: 0.9867 - val_loss: 0.1805 - val_Accuracy: 0.9388\n",
      "Epoch 5/5\n",
      "182/182 [==============================] - 80s 442ms/step - loss: 0.0159 - Accuracy: 0.9913 - val_loss: 0.1840 - val_Accuracy: 0.9296\n"
     ]
    }
   ],
   "source": [
    "history = train_model(train_tokens, train_tags, val_tokens, val_tags, batch_size = 32, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: When evaluating results for each epoch, be careful to not use custom metrics (F1/F2 score) directly through keras metric function that is calculated during training(fit) as it is done on batches (not together) and might show misleading results. Keras inbuilt metrics (tensorflow 2) use specialised built-in accumulators, and the computations are made properly. However, note it is possible to use custom metrics by other methods like backend utilities, callbacks, base layer API's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will plot the graph between the loss and number of epochs for training and validation set. To assess the number of epochs required and to avoid underfitting or overfitting, it is important to compare training and validation loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.figure(figsize = (8, 8))\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We observe our training loss starts becoming constant after 3 epochs and validation loss starts slightly increasing. We can increase the number of epochs to check and confirm the future trend of our losses, as our model is showing overfitting after 3-4 epochs.\n",
    "\n",
    "#### Note: We can use Callbacks to get a view on internal states and statistics of the model during training and thus help us in preventing overfitting, visualize training progress, debug your code, save checkpoints, generate logs etc. We have not used here for sake of simplicity and will demonstrate in later parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will be using CoNLL-2003 shared task as our evaluation metric. It measures the performance of the systems in terms of precision, recall and f1-score, where: \n",
    "- precision is the percentage of named entities found by the learning system that are correct. \n",
    "- Recall is the percentage of named entities present in the corpus that are found by the system. \n",
    "- A named entity is correct only if it is an exact match of the corresponding entity in the data file.\n",
    "#### We consider 3 scenarios here, namely :-\n",
    "- Surface string and entity type match\n",
    "- System hypothesized an entity\n",
    "- System misses an entity\n",
    "\n",
    "#### Note: We can use other evaluation metric for NER like Automatic Content Extraction (ACE) or Message Understanding Conference (MUC) which considers other scenarios for partial matches as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function which will calculate our evaluation metrics as per CoNLL-2003 evaluation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def _update_chunk(candidate, prev, current_tag, current_chunk, current_pos, prediction=False):\n",
    "    if candidate == 'B-' + current_tag:\n",
    "        if len(current_chunk) > 0 and len(current_chunk[-1]) == 1:\n",
    "                current_chunk[-1].append(current_pos - 1)\n",
    "        current_chunk.append([current_pos])\n",
    "    elif candidate == 'I-' + current_tag:\n",
    "        if prediction and (current_pos == 0 or current_pos > 0 and prev.split('-', 1)[-1] != current_tag):\n",
    "            current_chunk.append([current_pos])\n",
    "        if not prediction and (current_pos == 0 or current_pos > 0 and prev == 'O'):\n",
    "            current_chunk.append([current_pos])\n",
    "    elif current_pos > 0 and prev.split('-', 1)[-1] == current_tag:\n",
    "        if len(current_chunk) > 0:\n",
    "            current_chunk[-1].append(current_pos - 1)\n",
    "\n",
    "def _update_last_chunk(current_chunk, current_pos):\n",
    "    if len(current_chunk) > 0 and len(current_chunk[-1]) == 1:\n",
    "        current_chunk[-1].append(current_pos - 1)\n",
    "\n",
    "def _tag_precision_recall_f1(tp, fp, fn):\n",
    "    precision, recall, f1 = 0, 0, 0\n",
    "    if tp + fp > 0:\n",
    "        precision = tp / (tp + fp) * 100\n",
    "    if tp + fn > 0:\n",
    "        recall = tp / (tp + fn) * 100\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1\n",
    "\n",
    "def _aggregate_metrics(results, total_correct):\n",
    "    total_true_entities = 0\n",
    "    total_predicted_entities = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "    for tag, tag_metrics in results.items():\n",
    "        n_pred = tag_metrics['n_predicted_entities']\n",
    "        n_true = tag_metrics['n_true_entities']\n",
    "        total_true_entities += n_true\n",
    "        total_predicted_entities += n_pred\n",
    "        total_precision += tag_metrics['precision'] * n_pred\n",
    "        total_recall += tag_metrics['recall'] * n_true\n",
    "    \n",
    "    accuracy = 0\n",
    "    if total_true_entities > 0:\n",
    "        accuracy = total_correct / total_true_entities * 100\n",
    "    else:\n",
    "        print('CAUTION! Accuracy equals zero because there are no '\\\n",
    "              'correct entities. Check the correctness of your data.')\n",
    "    if total_predicted_entities > 0:\n",
    "        total_precision = total_precision / total_predicted_entities\n",
    "    total_recall = total_recall / total_true_entities\n",
    "    if total_precision + total_recall > 0:\n",
    "        total_f1 = 2 * total_precision * total_recall / (total_precision + total_recall)\n",
    "    return total_true_entities, total_predicted_entities, \\\n",
    "           total_precision, total_recall, total_f1, accuracy\n",
    "\n",
    "def _print_info(n_tokens, total_true_entities, total_predicted_entities, total_correct):\n",
    "    print('processed {len} tokens ' \\\n",
    "          'with {tot_true} phrases; ' \\\n",
    "          'found: {tot_pred} phrases; ' \\\n",
    "          'correct: {tot_cor}.\\n'.format(len=n_tokens,\n",
    "                                         tot_true=total_true_entities,\n",
    "                                         tot_pred=total_predicted_entities,\n",
    "                                         tot_cor=total_correct))\n",
    "\n",
    "def _print_metrics(accuracy, total_precision, total_recall, total_f1):\n",
    "    print('precision:  {tot_prec:.2f}%; ' \\\n",
    "          'recall:  {tot_recall:.2f}%; ' \\\n",
    "          'F1:  {tot_f1:.2f}%\\n'.format(acc=accuracy,\n",
    "                                           tot_prec=total_precision,\n",
    "                                           tot_recall=total_recall,\n",
    "                                           tot_f1=total_f1))\n",
    "\n",
    "def _print_tag_metrics(tag, tag_results):\n",
    "    print(('\\t%12s' % tag) + ': precision:  {tot_prec:6.2f}%; ' \\\n",
    "                               'recall:  {tot_recall:6.2f}%; ' \\\n",
    "                               'F1:  {tot_f1:6.2f}; ' \\\n",
    "                               'predicted:  {tot_predicted:4d}\\n'.format(tot_prec=tag_results['precision'],\n",
    "                                                                         tot_recall=tag_results['recall'],\n",
    "                                                                         tot_f1=tag_results['f1'],\n",
    "                                                                         tot_predicted=tag_results['n_predicted_entities']))\n",
    "\n",
    "def precision_recall_f1(y_true, y_pred, print_results=True, short_report=False):\n",
    "    # Find all tags\n",
    "    tags = sorted(set(tag[2:] for tag in y_true + y_pred if tag != 'O'))\n",
    "\n",
    "    results = OrderedDict((tag, OrderedDict()) for tag in tags)\n",
    "    n_tokens = len(y_true)\n",
    "    total_correct = 0\n",
    "\n",
    "    # For eval_conll_try we find all chunks in the ground truth and prediction\n",
    "    # For each chunk we store starting and ending indices\n",
    "    for tag in tags:\n",
    "        true_chunk = list()\n",
    "        predicted_chunk = list()\n",
    "        for position in range(n_tokens):\n",
    "            _update_chunk(y_true[position], y_true[position - 1], tag, true_chunk, position)\n",
    "            _update_chunk(y_pred[position], y_pred[position - 1], tag, predicted_chunk, position, True)\n",
    "\n",
    "        _update_last_chunk(true_chunk, position)\n",
    "        _update_last_chunk(predicted_chunk, position)\n",
    "\n",
    "        # Then we find all correctly classified intervals\n",
    "        # True positive results\n",
    "        tp = sum(chunk in predicted_chunk for chunk in true_chunk)\n",
    "        total_correct += tp\n",
    "\n",
    "        # And then just calculate errors of the first and second kind\n",
    "        # False negative\n",
    "        fn = len(true_chunk) - tp\n",
    "        # False positive\n",
    "        fp = len(predicted_chunk) - tp\n",
    "        precision, recall, f1 = _tag_precision_recall_f1(tp, fp, fn)\n",
    "\n",
    "        results[tag]['precision'] = precision\n",
    "        results[tag]['recall'] = recall\n",
    "        results[tag]['f1'] = f1\n",
    "        results[tag]['n_predicted_entities'] = len(predicted_chunk)\n",
    "        results[tag]['n_true_entities'] = len(true_chunk)\n",
    "\n",
    "    total_true_entities, total_predicted_entities, \\\n",
    "           total_precision, total_recall, total_f1, accuracy = _aggregate_metrics(results, total_correct)\n",
    "\n",
    "    if print_results:\n",
    "        _print_info(n_tokens, total_true_entities, total_predicted_entities, total_correct)\n",
    "        _print_metrics(accuracy, total_precision, total_recall, total_f1)\n",
    "\n",
    "        if not short_report:\n",
    "            for tag, tag_results in results.items():\n",
    "                _print_tag_metrics(tag, tag_results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tags(token_idxs_):\n",
    "    \"\"\"Performs predictions and transforms indices to tokens and tags.\"\"\"\n",
    "    \n",
    "    token_idxs_batch = np.expand_dims(token_idxs_,0)\n",
    "    tag_idxs_batch = model.predict(token_idxs_batch)\n",
    "    tag_idxs_batch = np.argmax(tag_idxs_batch, axis = -1)\n",
    "\n",
    "    tags_batch, tokens_batch = [], []\n",
    "    for tag_idxs, token_idxs in zip(tag_idxs_batch, token_idxs_batch):\n",
    "        tags, tokens = [], []\n",
    "        for tag_idx, token_idx in zip(tag_idxs, token_idxs):            \n",
    "            tags.append(idx2tag[tag_idx])\n",
    "            tokens.append(idx2token[token_idx])\n",
    "        tags_batch.append(tags)\n",
    "        tokens_batch.append(tokens)        \n",
    "    return tags_batch, tokens_batch\n",
    "    \n",
    "    \n",
    "def eval_conll(tokens, tags, short_report = True):\n",
    "    \"\"\"Computes NER quality measures using CONLL shared task script.\"\"\"\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for x_batch, y_batch in zip(tokens, tags):\n",
    "        x_batch_id = words2idxs(x_batch)\n",
    "        y_batch_id = tags2idxs(y_batch)\n",
    "        tags_batch, tokens_batch = predict_tags(x_batch_id)\n",
    "        y_true_batch = np.expand_dims(y_batch_id,0)     \n",
    "        \n",
    "        predicted_tags = []\n",
    "        ground_truth_tags = []\n",
    "        for gt_tag_idx, pred_tag, token in zip(y_true_batch[0], tags_batch[0], tokens_batch[0]): \n",
    "            if token != '<PAD>':\n",
    "                ground_truth_tags.append(idx2tag[gt_tag_idx])\n",
    "                predicted_tags.append(pred_tag)\n",
    "\n",
    "        # We extend every prediction and ground truth sequence with 'O' tag\n",
    "        # to indicate a possible end of entity.\n",
    "        y_true.extend(ground_truth_tags + ['O'])\n",
    "        y_pred.extend(predicted_tags + ['O'])\n",
    "          \n",
    "    results = precision_recall_f1(y_true, y_pred, print_results = True, short_report = short_report)\n",
    "    return (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After defining  our evaluation metrics, we can finally evaualte our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 11742 tokens with 425 phrases; found: 457 phrases; correct: 257.\n",
      "\n",
      "precision:  56.24%; recall:  60.47%; F1:  58.28%\n",
      "\n",
      "\t     company: precision:   65.57%; recall:   70.18%; F1:   67.80; predicted:    61\n",
      "\n",
      "\t    facility: precision:   41.30%; recall:   46.34%; F1:   43.68; predicted:    46\n",
      "\n",
      "\t     geo-loc: precision:   72.80%; recall:   75.21%; F1:   73.98; predicted:   125\n",
      "\n",
      "\t       movie: precision:   50.00%; recall:   25.00%; F1:   33.33; predicted:     4\n",
      "\n",
      "\t musicartist: precision:   36.36%; recall:   25.00%; F1:   29.63; predicted:    11\n",
      "\n",
      "\t       other: precision:   37.50%; recall:   47.37%; F1:   41.86; predicted:    96\n",
      "\n",
      "\t      person: precision:   68.42%; recall:   74.29%; F1:   71.23; predicted:    76\n",
      "\n",
      "\t     product: precision:   36.36%; recall:   25.00%; F1:   29.63; predicted:    11\n",
      "\n",
      "\t  sportsteam: precision:   37.50%; recall:   47.37%; F1:   41.86; predicted:    24\n",
      "\n",
      "\t      tvshow: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results = eval_conll(test_tokens, test_tags, short_report = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We observe a F1 score of about 58%. We can conduct more experiments to tune our hyperparameters and compare our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Despite the fact that we used small training corpora (in comparison with usual sizes of corpora in Deep Learning), our results are quite good. In addition, in this task there are many possible named entities and for some of them we have only several dozens of trainig examples, which is definately small. However, the implemented model outperforms classical CRFs for this task. Even better results could be obtained by some combinations of several types of methods and other techniques or model architectures and by carefully selecting the values of hyperparameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
